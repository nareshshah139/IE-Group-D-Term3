{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the model\n",
      "Predicting Probabilities\n",
      "Computing AUC\n",
      "Best AUC train=0.913128 (round=799), test=0.839790 (round=744)\n",
      "Validation\n",
      "0    0.017874\n",
      "1    0.012916\n",
      "2    0.014823\n",
      "3    0.161807\n",
      "4    0.006301\n",
      "Name: xgb_valid, dtype: float32\n",
      "0.8284797407611536\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import auc\n",
    "from sklearn import metrics\n",
    "\n",
    "df = pd.read_csv('/Users/naresh/downloads/train.csv')\n",
    "#df_train = df_train[0:46020]\n",
    "#df_test = df_train[-30000:]\n",
    "msk = np.random.rand(len(df)) < 0.7\n",
    "df_train = df[msk]\n",
    "df_test = df[~msk]\n",
    "df_target = df_train['TARGET']\n",
    "df_train = df_train.drop(['TARGET', 'ID'], axis=1)\n",
    "df_test_target = df_test['TARGET']\n",
    "df_test = df_test.drop(['TARGET','ID'], axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "probs = pd.DataFrame()\n",
    "errors = pd.DataFrame()\n",
    "\n",
    "X_train = df_train\n",
    "y_train = df_target\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(X_train, y_train, test_size=0.3, random_state=0)\n",
    "learning_rate = 0.01\n",
    "n_estimators = 800\n",
    "max_depth = 6\n",
    "subsample = 0.9\n",
    "colsample_bytree = 0.85\n",
    "min_child_weight = 1  # default\n",
    "\n",
    "eval_metrics = ['auc']\n",
    "eval_sets = [(X_train, y_train), (X_test, y_test)]\n",
    "xgb_model = XGBClassifier(seed=0, learning_rate=learning_rate, n_estimators=n_estimators,\n",
    "                    min_child_weight=min_child_weight, max_depth=max_depth,\n",
    "                    colsample_bytree=colsample_bytree, subsample=subsample,nthread = -1)\n",
    "print(\"Fitting the model\")\n",
    "xgb = xgb_model.fit(X_train, y_train, eval_metric=eval_metrics, eval_set=eval_sets, verbose=False)\n",
    "    \n",
    "print(\"Predicting Probabilities\")\n",
    "probs['xgb'] = xgb.predict_proba(X_test)[:, -1]\n",
    "\n",
    "print(\"Computing AUC\")\n",
    "auc_test = [xgb.evals_result_['validation_%d' % i]['auc'] for i in range(len(eval_sets))]\n",
    "auc_test = np.array(auc_test, dtype=float).T\n",
    "\n",
    "auc_best_round = np.argmax(auc_test, axis=0)\n",
    "auc_best = [auc_test[auc_best_round[0], 0], auc_test[auc_best_round[1], 1]]\n",
    "\n",
    "print('Best AUC train=%f (round=%d), test=%f (round=%d)' % (auc_best[0], auc_best_round[0], auc_best[1], auc_best_round[1]))\n",
    "print('Validation')\n",
    "test_probs = pd.DataFrame()\n",
    "test_probs['xgb_valid'] = xgb.predict_proba(df_test)[:,-1]\n",
    "print(test_probs['xgb_valid'].head())\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(df_test_target, test_probs, pos_label=1)\n",
    "\n",
    "a = float(auc(fpr,tpr))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ZERO_VARIANCE_COLUMNS = [\n",
    "    'ind_var2_0', 'ind_var2', 'ind_var27_0', 'ind_var28_0', 'ind_var28', 'ind_var27', 'ind_var41', 'ind_var46_0',\n",
    "    'ind_var46', 'num_var27_0', 'num_var28_0', 'num_var28', 'num_var27', 'num_var41', 'num_var46_0', 'num_var46',\n",
    "    'saldo_var28', 'saldo_var27', 'saldo_var41', 'saldo_var46', 'imp_amort_var18_hace3', 'imp_amort_var34_hace3',\n",
    "    'imp_reemb_var13_hace3', 'imp_reemb_var33_hace3', 'imp_trasp_var17_out_hace3', 'imp_trasp_var33_out_hace3',\n",
    "    'num_var2_0_ult1', 'num_var2_ult1', 'num_reemb_var13_hace3', 'num_reemb_var33_hace3', 'num_trasp_var17_out_hace3',\n",
    "    'num_trasp_var33_out_hace3', 'saldo_var2_ult1', 'saldo_medio_var13_medio_hace3'\n",
    "]\n",
    "\n",
    "CORRELATED_COLUMNS = [\n",
    "    'ind_var29_0', 'ind_var29', 'num_var6', 'num_var29', 'ind_var13_medio', 'num_var13_medio_0', 'num_var13_medio',\n",
    "    'num_meses_var13_medio_ult3', 'ind_var18', 'num_var18_0', 'num_var18', 'num_var20_0', 'num_var20', 'ind_var26',\n",
    "    'ind_var25', 'ind_var32', 'ind_var34', 'ind_var37', 'ind_var39', 'num_var29_0', 'delta_imp_amort_var18_1y3',\n",
    "    'num_var26', 'num_var25', 'num_var32', 'num_var34', 'delta_imp_amort_var34_1y3', 'num_var37', 'num_var39',\n",
    "    'saldo_var29', 'saldo_medio_var13_medio_ult1', 'delta_num_aport_var13_1y3', 'delta_num_aport_var17_1y3',\n",
    "    'delta_num_aport_var33_1y3', 'delta_num_reemb_var13_1y3', 'num_reemb_var13_ult1', 'delta_num_reemb_var17_1y3',\n",
    "    'delta_num_reemb_var33_1y3', 'num_reemb_var33_ult1', 'delta_num_trasp_var17_in_1y3',\n",
    "    'delta_num_trasp_var17_out_1y3', 'delta_num_trasp_var33_in_1y3', 'delta_num_trasp_var33_out_1y3',\n",
    "    'num_trasp_var33_out_ult1', 'delta_num_venta_var44_1y3'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naresh/Downloads/scikit-learn-master/sklearn/grid_search.py:43: DeprecationWarning: This module has been deprecated in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.83190, std: 0.00862, params: {'max_depth': 3, 'min_child_weight': 1},\n",
       "  mean: 0.83239, std: 0.00846, params: {'max_depth': 3, 'min_child_weight': 3},\n",
       "  mean: 0.83186, std: 0.00852, params: {'max_depth': 3, 'min_child_weight': 5},\n",
       "  mean: 0.82965, std: 0.00897, params: {'max_depth': 5, 'min_child_weight': 1},\n",
       "  mean: 0.82928, std: 0.01052, params: {'max_depth': 5, 'min_child_weight': 3},\n",
       "  mean: 0.82934, std: 0.00939, params: {'max_depth': 5, 'min_child_weight': 5},\n",
       "  mean: 0.82435, std: 0.00783, params: {'max_depth': 7, 'min_child_weight': 1},\n",
       "  mean: 0.82321, std: 0.00914, params: {'max_depth': 7, 'min_child_weight': 3},\n",
       "  mean: 0.82461, std: 0.00924, params: {'max_depth': 7, 'min_child_weight': 5},\n",
       "  mean: 0.81612, std: 0.00841, params: {'max_depth': 9, 'min_child_weight': 1},\n",
       "  mean: 0.82074, std: 0.00813, params: {'max_depth': 9, 'min_child_weight': 3},\n",
       "  mean: 0.82099, std: 0.01036, params: {'max_depth': 9, 'min_child_weight': 5}],\n",
       " {'max_depth': 3, 'min_child_weight': 3},\n",
       " 0.83239438350394512)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "param_test1 = {\n",
    " 'max_depth': [i for i in range(3,10,2)],\n",
    " 'min_child_weight':[i for i in range(1,6,2)]\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch1.fit(X_train,y_train)\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naresh/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/naresh/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15977\n",
      "Fitting the model\n",
      "Predicting Probabilities\n",
      "Computing AUC\n",
      "Best AUC train=0.868257 (round=799), test=0.847360 (round=799)\n",
      "Validation\n",
      "{'num_op_var39_ult3': 2, 'ind_var12_0': 9, 'ind_var30_0': 6, 'saldo_medio_var8_ult3': 2, 'var38': 670, 'saldo_medio_var12_ult3': 11, 'num_op_var41_ult1': 9, 'num_op_var41_comer_ult3': 7, 'saldo_var42': 38, 'imp_op_var41_efect_ult1': 81, 'saldo_var5': 79, 'num_op_var39_efect_ult3': 2, 'imp_op_var41_comer_ult1': 30, 'saldo_medio_var5_ult1': 58, 'num_op_var41_hace2': 14, 'num_var22_ult1': 187, 'num_var43_recib_ult1': 3, 'ind_var43_recib_ult1': 1, 'num_var39_0': 1, 'var3': 90, 'saldo_medio_var8_hace2': 2, 'imp_op_var39_efect_ult1': 22, 'ind_var24_0': 1, 'num_meses_var5_ult3': 58, 'ind_var25_0': 2, 'num_op_var39_hace2': 6, 'num_med_var22_ult3': 21, 'saldo_medio_var12_ult1': 2, 'saldo_var37': 60, 'num_med_var45_ult3': 29, 'ind_var39_0': 1, 'num_var13': 1, 'imp_op_var39_comer_ult1': 14, 'num_var43_emit_ult1': 1, 'imp_trans_var37_ult1': 42, 'num_op_var39_comer_ult1': 4, 'imp_ent_var16_ult1': 8, 'num_var12_0': 1, 'num_var8_0': 5, 'saldo_var25': 11, 'ind_var13_0': 3, 'ind_var8_0': 65, 'saldo_medio_var5_hace2': 188, 'imp_op_var41_efect_ult3': 148, 'imp_op_var39_efect_ult3': 75, 'num_op_var39_efect_ult1': 2, 'saldo_medio_var5_ult3': 240, 'saldo_var30': 608, 'num_op_var41_efect_ult3': 5, 'num_var45_hace2': 52, 'num_var45_hace3': 188, 'num_var22_hace3': 67, 'imp_op_var41_comer_ult3': 8, 'saldo_medio_var5_hace3': 244, 'ind_var13': 1, 'num_trasp_var11_ult1': 1, 'imp_op_var41_ult1': 52, 'num_var30_0': 12, 'imp_op_var39_ult1': 8, 'num_op_var41_ult3': 7, 'num_ent_var16_ult1': 24, 'var36': 13, 'saldo_medio_var8_ult1': 1, 'num_var37_0': 6, 'ind_var9_ult1': 2, 'ind_var26_cte': 8, 'num_var30': 2, 'imp_op_var39_comer_ult3': 9, 'num_var45_ult3': 59, 'num_op_var41_comer_ult1': 6, 'num_var22_ult3': 184, 'num_op_var39_hace3': 1, 'num_meses_var39_vig_ult3': 43, 'saldo_var8': 21, 'num_zero': 137, 'ind_var25': 2, 'ind_var25_cte': 10, 'saldo_medio_var8_hace3': 3, 'num_var45_ult1': 13, 'num_var4': 28, 'var15': 949, 'num_var42_0': 44, 'imp_var43_emit_ult1': 9, 'num_var22_hace2': 66, 'num_var35': 4, 'var21': 4, 'num_op_var39_comer_ult3': 8}\n"
     ]
    }
   ],
   "source": [
    "from xgboost import plot_importance\n",
    "\n",
    "#df_train = df_train.drop(['ind_var2_0', 'ind_var2', 'ind_var27_0', 'ind_var28_0', 'ind_var28', 'ind_var27', 'ind_var41', 'ind_var46_0',\n",
    "    #'ind_var46', 'num_var27_0', 'num_var28_0', 'num_var28', 'num_var27', 'num_var41', 'num_var46_0', 'num_var46',\n",
    "    #'saldo_var28', 'saldo_var27', 'saldo_var41', 'saldo_var46', 'imp_amort_var18_hace3', 'imp_amort_var34_hace3',\n",
    "    #'imp_reemb_var13_hace3', 'imp_reemb_var33_hace3', 'imp_trasp_var17_out_hace3', 'imp_trasp_var33_out_hace3',\n",
    "    #'num_var2_0_ult1', 'num_var2_ult1', 'num_reemb_var13_hace3', 'num_reemb_var33_hace3', 'num_trasp_var17_out_hace3',\n",
    "    #'num_trasp_var33_out_hace3', 'saldo_var2_ult1', 'saldo_medio_var13_medio_hace3'],axis = 1)\n",
    "#df_train = df_train.drop(['ind_var29_0', 'ind_var29', 'num_var6', 'num_var29', 'ind_var13_medio', 'num_var13_medio_0', 'num_var13_medio',\n",
    "    #'num_meses_var13_medio_ult3', 'ind_var18', 'num_var18_0', 'num_var18', 'num_var20_0', 'num_var20', 'ind_var26',\n",
    "    #'ind_var25', 'ind_var32', 'ind_var34', 'ind_var37', 'ind_var39', 'num_var29_0', 'delta_imp_amort_var18_1y3',\n",
    "    #'num_var26', 'num_var25', 'num_var32', 'num_var34', 'delta_imp_amort_var34_1y3', 'num_var37', 'num_var39',\n",
    "    #'saldo_var29', 'saldo_medio_var13_medio_ult1', 'delta_num_aport_var13_1y3', 'delta_num_aport_var17_1y3',\n",
    "    #'delta_num_aport_var33_1y3', 'delta_num_reemb_var13_1y3', 'num_reemb_var13_ult1', 'delta_num_reemb_var17_1y3',\n",
    "    #'delta_num_reemb_var33_1y3', 'num_reemb_var33_ult1', 'delta_num_trasp_var17_in_1y3',\n",
    "    #'delta_num_trasp_var17_out_1y3', 'delta_num_trasp_var33_in_1y3', 'delta_num_trasp_var33_out_1y3',\n",
    "    #'num_trasp_var33_out_ult1', 'delta_num_venta_var44_1y3'],axis = 1)\n",
    "#df_test = df_test.drop(['ind_var29_0', 'ind_var29', 'num_var6', 'num_var29', 'ind_var13_medio', 'num_var13_medio_0', 'num_var13_medio',\n",
    "    #'num_meses_var13_medio_ult3', 'ind_var18', 'num_var18_0', 'num_var18', 'num_var20_0', 'num_var20', 'ind_var26',\n",
    "    #'ind_var25', 'ind_var32', 'ind_var34', 'ind_var37', 'ind_var39', 'num_var29_0', 'delta_imp_amort_var18_1y3',\n",
    "    #'num_var26', 'num_var25', 'num_var32', 'num_var34', 'delta_imp_amort_var34_1y3', 'num_var37', 'num_var39',\n",
    "    #'saldo_var29', 'saldo_medio_var13_medio_ult1', 'delta_num_aport_var13_1y3', 'delta_num_aport_var17_1y3',\n",
    "    #'delta_num_aport_var33_1y3', 'delta_num_reemb_var13_1y3', 'num_reemb_var13_ult1', 'delta_num_reemb_var17_1y3',\n",
    "    ##'delta_num_reemb_var33_1y3', 'num_reemb_var33_ult1', 'delta_num_trasp_var17_in_1y3',\n",
    "    #'delta_num_trasp_var17_out_1y3', 'delta_num_trasp_var33_in_1y3', 'delta_num_trasp_var33_out_1y3',\n",
    "    #'num_trasp_var33_out_ult1', 'delta_num_venta_var44_1y3'], axis = 1)\n",
    "#df_test = df_test.drop(['ind_var2_0', 'ind_var2', 'ind_var27_0', 'ind_var28_0', 'ind_var28', 'ind_var27', 'ind_var41', 'ind_var46_0',\n",
    "    #'ind_var46', 'num_var27_0', 'num_var28_0', 'num_var28', 'num_var27', 'num_var41', 'num_var46_0', 'num_var46',\n",
    "    #'saldo_var28', 'saldo_var27', 'saldo_var41', 'saldo_var46', 'imp_amort_var18_hace3', 'imp_amort_var34_hace3',\n",
    "    ##'imp_reemb_var13_hace3', 'imp_reemb_var33_hace3', 'imp_trasp_var17_out_hace3', 'imp_trasp_var33_out_hace3',\n",
    "    #'num_var2_0_ult1', 'num_var2_ult1', 'num_reemb_var13_hace3', 'num_reemb_var33_hace3', 'num_trasp_var17_out_hace3',\n",
    "    #'num_trasp_var33_out_hace3', 'saldo_var2_ult1', 'saldo_medio_var13_medio_hace3'],axis = 1)\n",
    "\n",
    "#Run XGBoost model\n",
    "\n",
    "\n",
    "X_train['num_zero'] = (X_train == 0).sum(axis=1)\n",
    "X_test['num_zero'] = (X_test == 0).sum(axis=1)\n",
    "\n",
    "print(len(X_test))\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(X_train, y_train, test_size=0.3, random_state=0)\n",
    "learning_rate = 0.01\n",
    "n_estimators = 800\n",
    "max_depth = 3\n",
    "subsample = 0.9\n",
    "colsample_bytree = 0.85\n",
    "min_child_weight = 3  # default\n",
    "\n",
    "eval_metrics = ['auc']\n",
    "eval_sets = [(X_train, y_train), (X_test, y_test)]\n",
    "xgb_model = XGBClassifier(seed=0, learning_rate=learning_rate, n_estimators=n_estimators,\n",
    "                    min_child_weight=min_child_weight, max_depth=max_depth,\n",
    "                    colsample_bytree=colsample_bytree, subsample=subsample,nthread = -1)\n",
    "print(\"Fitting the model\")\n",
    "xgb = xgb_model.fit(X_train, y_train, eval_metric=eval_metrics, eval_set=eval_sets, verbose=False)\n",
    "    \n",
    "print(\"Predicting Probabilities\")\n",
    "probs_new = pd.DataFrame()\n",
    "probs_new['xgb'] = xgb_model.predict_proba(X_test)[:, -1]\n",
    "\n",
    "print(\"Computing AUC\")\n",
    "auc_test = [xgb.evals_result_['validation_%d' % i]['auc'] for i in range(len(eval_sets))]\n",
    "auc_test = np.array(auc_test, dtype=float).T\n",
    "\n",
    "auc_best_round = np.argmax(auc_test, axis=0)\n",
    "auc_best = [auc_test[auc_best_round[0], 0], auc_test[auc_best_round[1], 1]]\n",
    "\n",
    "print('Best AUC train=%f (round=%d), test=%f (round=%d)' % (auc_best[0], auc_best_round[0], auc_best[1], auc_best_round[1]))\n",
    "print('Validation')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "importances = xgb.booster().get_fscore()\n",
    "print(importances)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.15667121\n",
      "Iteration 2, loss = 0.13831011\n",
      "Iteration 3, loss = 0.13465906\n",
      "Iteration 4, loss = 0.13096057\n",
      "Iteration 5, loss = 0.12976440\n",
      "Iteration 6, loss = 0.12909735\n",
      "Iteration 7, loss = 0.12704487\n",
      "Iteration 8, loss = 0.12639400\n",
      "Iteration 9, loss = 0.12465343\n",
      "Iteration 10, loss = 0.12434712\n",
      "Iteration 11, loss = 0.12430869\n",
      "Iteration 12, loss = 0.12288689\n",
      "Iteration 13, loss = 0.12077099\n",
      "Iteration 14, loss = 0.11990932\n",
      "Iteration 15, loss = 0.11955826\n",
      "Iteration 16, loss = 0.11787604\n",
      "Iteration 17, loss = 0.11787424\n",
      "Iteration 18, loss = 0.11760271\n",
      "Iteration 19, loss = 0.11634629\n",
      "Iteration 20, loss = 0.11438073\n",
      "Iteration 21, loss = 0.11408426\n",
      "Iteration 22, loss = 0.11305997\n",
      "Iteration 23, loss = 0.11261563\n",
      "Iteration 24, loss = 0.11136189\n",
      "Iteration 25, loss = 0.11126067\n",
      "Iteration 26, loss = 0.11069287\n",
      "Iteration 27, loss = 0.11169554\n",
      "Iteration 28, loss = 0.11177548\n",
      "Iteration 29, loss = 0.11076092\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "22765\n",
      "11184\n",
      "0    0.000669\n",
      "1    0.198549\n",
      "2    0.191113\n",
      "3    0.022911\n",
      "4    0.218507\n",
      "Name: mlp, dtype: float64\n",
      "11184\n",
      "0.770036588314486\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "X_train = StandardScaler().fit_transform(X_train)\n",
    "\n",
    "nn = MLPClassifier(hidden_layer_sizes=(200,50), max_iter=100, alpha=1e-4,\n",
    "                    algorithm='adam', verbose=10, tol=1e-4, random_state=1,\n",
    "                    learning_rate= 'adaptive')\n",
    "X_test = StandardScaler().fit_transform(X_test)\n",
    "df_test = StandardScaler().fit_transform(df_test)\n",
    "\n",
    "nn.fit(X_train, y_train)\n",
    "test_probs1 = pd.DataFrame()\n",
    "test_probs1['mlp'] = nn.predict_proba(X_test)[:, -1]\n",
    "print(len(df_test))\n",
    "print(len(X_test))\n",
    "print(test_probs1['mlp'].head())\n",
    "print(len(test_probs1['mlp']))\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, test_probs1, pos_label=1)\n",
    "\n",
    "\n",
    "a = float(auc(fpr,tpr))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8431245477008673\n"
     ]
    }
   ],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, 0.2*test_probs1['mlp']+0.8*probs_new['xgb'])\n",
    "a = float(auc(fpr,tpr))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.15667121\n",
      "Iteration 2, loss = 0.13831011\n",
      "Iteration 3, loss = 0.13465906\n",
      "Iteration 4, loss = 0.13096057\n",
      "Iteration 5, loss = 0.12976440\n",
      "Iteration 6, loss = 0.12909735\n",
      "Iteration 7, loss = 0.12704487\n",
      "Iteration 8, loss = 0.12639400\n",
      "Iteration 9, loss = 0.12465343\n",
      "Iteration 10, loss = 0.12434712\n",
      "Iteration 11, loss = 0.12430869\n",
      "Iteration 12, loss = 0.12288689\n",
      "Iteration 13, loss = 0.12077099\n",
      "Iteration 14, loss = 0.11990932\n",
      "Iteration 15, loss = 0.11955826\n",
      "Iteration 16, loss = 0.11787604\n",
      "Iteration 17, loss = 0.11787424\n",
      "Iteration 18, loss = 0.11760271\n",
      "Iteration 19, loss = 0.11634629\n",
      "Iteration 20, loss = 0.11438073\n",
      "Iteration 21, loss = 0.11408426\n",
      "Iteration 22, loss = 0.11305997\n",
      "Iteration 23, loss = 0.11261563\n",
      "Iteration 24, loss = 0.11136189\n",
      "Iteration 25, loss = 0.11126067\n",
      "Iteration 26, loss = 0.11069287\n",
      "Iteration 27, loss = 0.11169554\n",
      "Iteration 28, loss = 0.11177548\n",
      "Iteration 29, loss = 0.11076092\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = AdaBoostClassifier(n_estimators=100)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "clf2 = RandomForestClassifier(n_estimators=100, max_depth=5, min_samples_split=1, random_state=0)\n",
    "clf2.fit(X_train,y_train)\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('nn',nn ), ('xgbt', xgb_model),('ada',clf),('rf',clf2)], voting='soft', weights=[1,2,0.5,0.5])\n",
    "eclf.fit(X_train,y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_probs2 = pd.DataFrame()\n",
    "test_probs2['voting'] = eclf.predict_proba(df_test)[:, -1]\n",
    "print(test_probs2['voting'].head())\n",
    "print()\n",
    "fpr, tpr, thresholds = metrics.roc_curve(df_test_target, test_probs2, pos_label=1)\n",
    "a = float(auc(fpr,tpr))\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "param_test1 = {\n",
    " 'max_depth': [i for i in range(3,12,1)],\n",
    " 'colsample_bytree':np.linspace(0.8,0.9,1)\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch1.fit(X_train,y_train)\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_final = pd.read_csv('/Users/naresh/downloads/sample_submission.csv')\n",
    "df_tests = pd.read_csv('/Users/naresh/downloads/test.csv')\n",
    "\n",
    "\n",
    "\n",
    "df_final['TARGET'] = test_probs2\n",
    "print(df_final)\n",
    "print(df_tests.head(5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
