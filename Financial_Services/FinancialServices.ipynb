{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the model\n",
      "Predicting Probabilities\n",
      "Computing AUC\n",
      "Best AUC train=0.906529 (round=799), test=0.837780 (round=600)\n",
      "Validation\n",
      "0    0.027952\n",
      "1    0.004211\n",
      "2    0.012208\n",
      "3    0.014333\n",
      "4    0.008440\n",
      "Name: xgb_valid, dtype: float32\n",
      "0.8352413580087394\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import auc\n",
    "from sklearn import metrics\n",
    "\n",
    "df = pd.read_csv('/Users/naresh/downloads/train.csv')\n",
    "#df_train = df_train[0:46020]\n",
    "#df_test = df_train[-30000:]\n",
    "msk = np.random.rand(len(df)) < 0.7\n",
    "df_train = df[msk]\n",
    "df_test = df[~msk]\n",
    "df_target = df_train['TARGET']\n",
    "df_train = df_train.drop(['TARGET', 'ID'], axis=1)\n",
    "df_test_target = df_test['TARGET']\n",
    "df_test = df_test.drop(['TARGET','ID'], axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "probs = pd.DataFrame()\n",
    "errors = pd.DataFrame()\n",
    "\n",
    "X_train = df_train\n",
    "y_train = df_target\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(X_train, y_train, test_size=0.3, random_state=0)\n",
    "learning_rate = 0.01\n",
    "n_estimators = 800\n",
    "max_depth = 6\n",
    "subsample = 0.9\n",
    "colsample_bytree = 0.85\n",
    "min_child_weight = 1  # default\n",
    "\n",
    "eval_metrics = ['auc']\n",
    "eval_sets = [(X_train, y_train), (X_test, y_test)]\n",
    "xgb_model = XGBClassifier(seed=0, learning_rate=learning_rate, n_estimators=n_estimators,\n",
    "                    min_child_weight=min_child_weight, max_depth=max_depth,\n",
    "                    colsample_bytree=colsample_bytree, subsample=subsample,nthread = -1)\n",
    "print(\"Fitting the model\")\n",
    "xgb = xgb_model.fit(X_train, y_train, eval_metric=eval_metrics, eval_set=eval_sets, verbose=False)\n",
    "    \n",
    "print(\"Predicting Probabilities\")\n",
    "probs['xgb'] = xgb.predict_proba(X_test)[:, -1]\n",
    "\n",
    "print(\"Computing AUC\")\n",
    "auc_test = [xgb.evals_result_['validation_%d' % i]['auc'] for i in range(len(eval_sets))]\n",
    "auc_test = np.array(auc_test, dtype=float).T\n",
    "\n",
    "auc_best_round = np.argmax(auc_test, axis=0)\n",
    "auc_best = [auc_test[auc_best_round[0], 0], auc_test[auc_best_round[1], 1]]\n",
    "\n",
    "print('Best AUC train=%f (round=%d), test=%f (round=%d)' % (auc_best[0], auc_best_round[0], auc_best[1], auc_best_round[1]))\n",
    "print('Validation')\n",
    "test_probs = pd.DataFrame()\n",
    "test_probs['xgb_valid'] = xgb.predict_proba(df_test)[:,-1]\n",
    "print(test_probs['xgb_valid'].head())\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(df_test_target, test_probs, pos_label=1)\n",
    "\n",
    "a = float(auc(fpr,tpr))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "param_test1 = {\n",
    " 'max_depth': [i for i in range(3,10,2)],\n",
    " 'min_child_weight':[i for i in range(1,6,2)]\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch1.fit(X_train,y_train)\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.16352570\n",
      "Iteration 2, loss = 0.14177073\n",
      "Iteration 3, loss = 0.13801427\n",
      "Iteration 4, loss = 0.13677800\n",
      "Iteration 5, loss = 0.13627585\n",
      "Iteration 6, loss = 0.13420606\n",
      "Iteration 7, loss = 0.13236046\n",
      "Iteration 8, loss = 0.13122264\n",
      "Iteration 9, loss = 0.12953887\n",
      "Iteration 10, loss = 0.13353598\n",
      "Iteration 11, loss = 0.12928391\n",
      "Iteration 12, loss = 0.12813579\n",
      "Iteration 13, loss = 0.12660319\n",
      "Iteration 14, loss = 0.12531548\n",
      "Iteration 15, loss = 0.12946279\n",
      "Iteration 16, loss = 0.12634359\n",
      "Iteration 17, loss = 0.12359616\n",
      "Iteration 18, loss = 0.12153390\n",
      "Iteration 19, loss = 0.12203907\n",
      "Iteration 20, loss = 0.12845549\n",
      "Iteration 21, loss = 0.12023070\n",
      "Iteration 22, loss = 0.11848059\n",
      "Iteration 23, loss = 0.11748758\n",
      "Iteration 24, loss = 0.11763244\n",
      "Iteration 25, loss = 0.11491156\n",
      "Iteration 26, loss = 0.11648367\n",
      "Iteration 27, loss = 0.11425526\n",
      "Iteration 28, loss = 0.11420380\n",
      "Iteration 29, loss = 0.11053724\n",
      "Iteration 30, loss = 0.11048128\n",
      "Iteration 31, loss = 0.11776955\n",
      "Iteration 32, loss = 0.11136373\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "0    1.023034e-03\n",
      "1    7.855794e-08\n",
      "2    6.009416e-03\n",
      "3    2.218845e-01\n",
      "4    1.048265e-05\n",
      "Name: mlp, dtype: float64\n",
      "\n",
      "0.7772740935950471\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "X_train = StandardScaler().fit_transform(X_train)\n",
    "\n",
    "nn = MLPClassifier(hidden_layer_sizes=(200,200,50), max_iter=100, alpha=1e-4,\n",
    "                    algorithm='adam', verbose=10, tol=1e-4, random_state=1,\n",
    "                    learning_rate_init= 0.001)\n",
    "X_test = StandardScaler().fit_transform(X_test)\n",
    "df_test = StandardScaler().fit_transform(df_test)\n",
    "\n",
    "nn.fit(X_train, y_train)\n",
    "test_probs1 = pd.DataFrame()\n",
    "test_probs1['mlp'] = nn.predict_proba(df_test1)[:, -1]\n",
    "print(test_probs1['mlp'].head())\n",
    "print()\n",
    "fpr, tpr, thresholds = metrics.roc_curve(df_test_target, test_probs1, pos_label=1)\n",
    "\n",
    "\n",
    "a = float(auc(fpr,tpr))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.15999335\n",
      "Iteration 2, loss = 0.14222169\n",
      "Iteration 3, loss = 0.13778863\n",
      "Iteration 4, loss = 0.13639491\n",
      "Iteration 5, loss = 0.13546905\n",
      "Iteration 6, loss = 0.13368440\n",
      "Iteration 7, loss = 0.13218417\n",
      "Iteration 8, loss = 0.13058078\n",
      "Iteration 9, loss = 0.12937945\n",
      "Iteration 10, loss = 0.13287769\n",
      "Iteration 11, loss = 0.12860296\n",
      "Iteration 12, loss = 0.12750545\n",
      "Iteration 13, loss = 0.12638896\n",
      "Iteration 14, loss = 0.12586441\n",
      "Iteration 15, loss = 0.12917647\n",
      "Iteration 16, loss = 0.12461050\n",
      "Iteration 17, loss = 0.12260380\n",
      "Iteration 18, loss = 0.12221281\n",
      "Iteration 19, loss = 0.12201874\n",
      "Iteration 20, loss = 0.12959499\n",
      "Iteration 21, loss = 0.12285322\n",
      "Iteration 22, loss = 0.12027138\n",
      "Iteration 23, loss = 0.11900718\n",
      "Iteration 24, loss = 0.11889244\n",
      "Iteration 25, loss = 0.11775066\n",
      "Iteration 26, loss = 0.11767397\n",
      "Iteration 27, loss = 0.11603549\n",
      "Iteration 28, loss = 0.11543907\n",
      "Iteration 29, loss = 0.11398784\n",
      "Iteration 30, loss = 0.11326235\n",
      "Iteration 31, loss = 0.11928200\n",
      "Iteration 32, loss = 0.11544712\n",
      "Iteration 33, loss = 0.11517542\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "0    3.460072e-03\n",
      "1    3.120714e-08\n",
      "2    1.211819e-02\n",
      "3    2.064471e-01\n",
      "4    1.099564e-04\n",
      "Name: mlp, dtype: float64\n",
      "\n",
      "0.7806582840236687\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "X_train = StandardScaler().fit_transform(X_train)\n",
    "\n",
    "nn = MLPClassifier(hidden_layer_sizes=(200,50), max_iter=100, alpha=1e-4,\n",
    "                    algorithm='adam', verbose=10, tol=1e-4, random_state=1,\n",
    "                    learning_rate= 'adaptive')\n",
    "X_test = StandardScaler().fit_transform(X_test)\n",
    "df_test = StandardScaler().fit_transform(df_test)\n",
    "\n",
    "nn.fit(X_train, y_train)\n",
    "test_probs1 = pd.DataFrame()\n",
    "test_probs1['mlp'] = nn.predict_proba(df_test)[:, -1]\n",
    "print(test_probs1['mlp'].head())\n",
    "print()\n",
    "fpr, tpr, thresholds = metrics.roc_curve(df_test_target, test_probs1, pos_label=1)\n",
    "\n",
    "\n",
    "a = float(auc(fpr,tpr))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
